{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18479a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Standard libraries ----------------\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import shutil\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "# ---------------- Data handling ----------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "# ---------------- Machine learning & NLP ----------------\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import hdbscan\n",
    "import umap\n",
    "\n",
    "# ---------------- Deep learning & Transformers ----------------\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ---------------- Visualization ----------------\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b486f9",
   "metadata": {},
   "source": [
    "Embedding text from Parquet data frames using Gemma300m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345beb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Settings ----------------\n",
    "INPUT_PARQUET = \"output/raw_posts_kafka\"\n",
    "BASE_DIR = \"output/raw_posts_embeddings_gemma\"\n",
    "MODEL_ID = \"google/embeddinggemma-300m\"\n",
    "BATCH_SIZE = 256\n",
    "MAX_SEQ_LEN = 128\n",
    "NORMALIZE = False\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "# ---------------- NSFW / filtering ----------------\n",
    "NSFW_KEYWORDS = set([\n",
    "    \"porn\",\"sex\",\"nude\",\"sexy\",\"fuck\",\"cock\",\"cum\",\"blowjob\",\n",
    "    \"dick\",\"tits\",\"ass\",\"horny\",\"slut\",\"nsfw\",\"onlyfans\"\n",
    "])\n",
    "\n",
    "MULTILINGUAL_STOPWORDS = set([\n",
    "    \"the\",\"and\",\"a\",\"of\",\"in\",\"to\",\"is\",\"it\",\"for\",\"on\",\n",
    "    \"que\",\"de\",\"le\",\"la\",\"el\",\"en\",\"und\",\"der\",\"die\"\n",
    "])\n",
    "\n",
    "URL_PATTERN = re.compile(r\"(https?://\\S+|www\\.\\S+)\")\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\", \" \", text)\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text_words = [w for w in text.split() if w not in MULTILINGUAL_STOPWORDS]\n",
    "    return \" \".join(text_words)\n",
    "\n",
    "def is_meaningful(text):\n",
    "    if not re.search(r\"\\w\", text):\n",
    "        return False\n",
    "    tokens = text.split()\n",
    "    if len(tokens) == 0:\n",
    "        return False\n",
    "    url_count = sum(bool(URL_PATTERN.match(tok)) for tok in tokens)\n",
    "    if url_count / len(tokens) > 0.5:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def is_nsfw(text):\n",
    "    text_lower = text.lower()\n",
    "    return any(kw in text_lower for kw in NSFW_KEYWORDS)\n",
    "\n",
    "# ---------------- Load posts ----------------\n",
    "df = pd.read_parquet(INPUT_PARQUET, columns=[\"did\", \"rkey\", \"text\"])\n",
    "print(f\"Before filtering: {len(df)} posts.\")\n",
    "\n",
    "df[\"post_id\"] = df[\"did\"].astype(str) + \"/\" + df[\"rkey\"].astype(str)\n",
    "df = df[df[\"text\"].notna()]\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df = df[df[\"text\"].str.len() > 0]\n",
    "df[\"text_clean\"] = df[\"text\"].apply(preprocess)\n",
    "\n",
    "# ---------------- Preprocessing ----------------\n",
    "df = df[df[\"text_clean\"].apply(is_meaningful)]\n",
    "df = df[~df[\"text_clean\"].apply(is_nsfw)]\n",
    "df = df[df[\"text_clean\"].str.len() > 0]\n",
    "\n",
    "print(f\"After filtering: {len(df)} posts remain.\")\n",
    "\n",
    "# ---------------- Load model ----------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer(MODEL_ID, device=device,truncate_dim=256).eval()\n",
    "try:\n",
    "    model.max_seq_length = MAX_SEQ_LEN\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if device == \"cuda\":\n",
    "    try:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ---------------- Encode embeddings ----------------\n",
    "texts = df[\"text_clean\"].tolist()\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    prompt_name=\"Clustering\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=False,\n",
    "    convert_to_numpy=True\n",
    ").astype(np.float32)\n",
    "\n",
    "# ---------------- Validate embeddings ----------------\n",
    "finite_mask = np.isfinite(embeddings).all(axis=1)\n",
    "if not finite_mask.all():\n",
    "    n_bad = (~finite_mask).sum()\n",
    "    print(f\"Found {n_bad} rows with NaN/Inf; re-encoding just those rowsâ€¦\")\n",
    "    bad_idx = np.where(~finite_mask)[0]\n",
    "    bad_texts = [texts[i] for i in bad_idx]\n",
    "\n",
    "    fixed = model.encode(\n",
    "        bad_texts,\n",
    "        batch_size=max(64, BATCH_SIZE // 2),\n",
    "        show_progress_bar=True,\n",
    "        normalize_embeddings=False,\n",
    "        convert_to_numpy=True\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    embeddings[bad_idx] = fixed\n",
    "    assert np.isfinite(embeddings).all(), \"Still found NaN/Inf after repair\"\n",
    "\n",
    "if NORMALIZE:\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    nz = norms.squeeze() > 0\n",
    "    embeddings[nz] = embeddings[nz] / norms[nz]\n",
    "\n",
    "# ---------------- Save embeddings ----------------\n",
    "shutil.rmtree(BASE_DIR, ignore_errors=True)\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "emb_list_arrays = [pa.array(row, type=pa.float32()) for row in embeddings]\n",
    "table = pa.table({\n",
    "    \"post_id\": pa.array(df[\"post_id\"].tolist()),\n",
    "    \"text\": pa.array(df[\"text\"].tolist()),\n",
    "    \"text_clean\": pa.array(df[\"text_clean\"].tolist()),\n",
    "    \"embedding\": pa.array(emb_list_arrays, type=pa.list_(pa.float32()))\n",
    "})\n",
    "\n",
    "fmt = ds.ParquetFileFormat()\n",
    "opts = fmt.make_write_options(compression=os.environ.get(\"PARQUET_COMPRESSION\", \"zstd\"))\n",
    "\n",
    "ds.write_dataset(\n",
    "    data=table,\n",
    "    base_dir=BASE_DIR,\n",
    "    format=fmt,\n",
    "    file_options=opts,\n",
    "    existing_data_behavior=\"overwrite_or_ignore\"\n",
    ")\n",
    "\n",
    "print(f\"Wrote dataset to directory: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eebbbda",
   "metadata": {},
   "source": [
    "Cluster the posts and prep for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80c31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embeddings...\n",
      "Normalizing Embeddings...\n",
      "Dimensionality reduction...\n",
      "Embedding Dimension ---> 64D...\n",
      "Dimensionality reduction done in 80.57 seconds\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\",message=\"n_jobs value .* overridden to 1 by setting random_state\")\n",
    "BASE_DIR = \"output/raw_posts_embeddings_gemma\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "# ---------------- Load embeddings ----------------\n",
    "print(\"Loading Embeddings...\")\n",
    "dataset = ds.dataset(BASE_DIR, format=\"parquet\")\n",
    "table = dataset.to_table(columns=[\"post_id\", \"text\", \"text_clean\", \"embedding\"])\n",
    "\n",
    "post_id = table.column(\"post_id\").to_pylist()\n",
    "texts = table.column(\"text\").to_pylist()\n",
    "texts_clean = table.column(\"text_clean\").to_pylist()\n",
    "embeddings = np.vstack(table.column(\"embedding\").to_pylist()).astype(np.float32)\n",
    "\n",
    "# Normalize embeddings\n",
    "print(\"Normalizing Embeddings...\")\n",
    "norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "nonzero = norms.squeeze() > 0\n",
    "embeddings[nonzero] /= norms[nonzero]\n",
    "\n",
    "#remove comment below if you want dim reduction before clustering or not\n",
    "\n",
    "# ---------------- Dimensionality reduction ----------------\n",
    "\n",
    "print(\"Dimensionality reduction...\")\n",
    "print(\"Embedding Dimension ---> 64D...\")\n",
    "start_time = time.time()\n",
    "reducer_high = umap.UMAP(random_state=2025,n_components=64, metric=\"cosine\")\n",
    "X_64d = reducer_high.fit_transform(embeddings)\n",
    "end_time = time.time()\n",
    "print(f\"Dimensionality reduction done in {end_time - start_time:.2f} seconds\")\n",
    "embeddings = X_64d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1771788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDBSCAN clustering...\n",
      "Number of embeddings: 56788\n",
      "HDBSCAN clustering done in 76.04 seconds\n",
      "Found 98 clusters\n",
      "Reducing cluster centroids to 2D...\n"
     ]
    }
   ],
   "source": [
    "# ---------------- HDBSCAN clustering ---------------- \n",
    "print(\"HDBSCAN clustering...\")\n",
    "print(f\"Number of embeddings: {len(embeddings)}\")\n",
    "start_time = time.time()\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=40,metric=\"euclidean\",cluster_selection_method=\"eom\")\n",
    "labels = clusterer.fit_predict(embeddings) \n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"HDBSCAN clustering done in {end_time - start_time:.2f} seconds\")\n",
    "# ---------------- Group clusters ----------------\n",
    "clusters = defaultdict(list)\n",
    "for i, c in enumerate(labels):\n",
    "    if c == -1:\n",
    "        continue\n",
    "    clusters[c].append(i)\n",
    "\n",
    "print(f\"Found {len(clusters)} clusters\")\n",
    "# ---------------- Compute cluster centroids in embedding space ----------------\n",
    "cluster_ids = []\n",
    "cluster_centroids = []\n",
    "\n",
    "for c, idxs in clusters.items():\n",
    "    cluster_ids.append(c)\n",
    "    cluster_centroids.append(embeddings[idxs].mean(axis=0))\n",
    "\n",
    "cluster_centroids = np.vstack(cluster_centroids)\n",
    "\n",
    "# ---------------- Reduce centroids to 2D for visualization ----------------\n",
    "print(\"Reducing cluster centroids to 2D...\")\n",
    "reducer_2d = umap.UMAP(random_state=2025,n_components=2,metric=\"cosine\",  min_dist=0.1,spread=1.0,)\n",
    "X_2d_centroids = reducer_2d.fit_transform(cluster_centroids)\n",
    "cluster_positions = {c: X_2d_centroids[i] for i, c in enumerate(cluster_ids)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd89c98",
   "metadata": {},
   "source": [
    "Create labels for clusters using GenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21294b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cluster labels with Gemma 2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7464ddc20be64ae7bca240d484d6aee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------- Gemma 2 Cluster Labeling ----------------\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Generating cluster labels with Gemma 2...\")\n",
    "model_name = \"google/gemma-2-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model = model.to(\"cuda\")\n",
    "device = model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dfde41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Cluster: 0\n",
      "Cluster: 1\n",
      "Cluster: 2\n",
      "Cluster: 3\n",
      "Cluster: 4\n",
      "Cluster: 5\n",
      "Cluster: 6\n",
      "Cluster: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m top_posts \u001b[38;5;241m=\u001b[39m [texts_clean[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m random_idx]\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Generate a label or summary for the cluster\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m label_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_cluster_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_posts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Store cluster metadata\u001b[39;00m\n\u001b[0;32m     67\u001b[0m centroid_2d \u001b[38;5;241m=\u001b[39m X_2d_centroids[i]\n",
      "Cell \u001b[1;32mIn[20], line 27\u001b[0m, in \u001b[0;36mgenerate_cluster_label\u001b[1;34m(posts, max_new_tokens)\u001b[0m\n\u001b[0;32m     18\u001b[0m assistant_prompt \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide a concise topic.\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     20\u001b[0m chat_prompt \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[0;32m     21\u001b[0m     [user_prompt, assistant_prompt],\n\u001b[0;32m     22\u001b[0m     tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     25\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)  \n\u001b[1;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchat_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m label \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m label \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, label)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[0;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[1;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2566\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2570\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2571\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2579\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2784\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2781\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[1;32m-> 2784\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2785\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[1;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\models\\gemma2\\modeling_gemma2.py:549\u001b[0m, in \u001b[0;36mGemma2ForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    546\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[0;32m    547\u001b[0m )\n\u001b[0;32m    548\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m--> 549\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\utils\\generic.py:1064\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1061\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1064\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m     kwargs_without_recordable \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\models\\gemma2\\modeling_gemma2.py:464\u001b[0m, in \u001b[0;36mGemma2Model.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    462\u001b[0m     all_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (hidden_states,)\n\u001b[1;32m--> 464\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning_once(message)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\models\\gemma2\\modeling_gemma2.py:325\u001b[0m, in \u001b[0;36mGemma2DecoderLayer.forward\u001b[1;34m(self, hidden_states, position_embeddings, attention_mask, position_ids, past_key_values, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    324\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 325\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_feedforward_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m    327\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_feedforward_layernorm(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\models\\gemma2\\modeling_gemma2.py:60\u001b[0m, in \u001b[0;36mGemma2RMSNorm.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 60\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# Llama does x.to(float16) * w whilst Gemma2 is (x * w).to(float16)\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# See https://github.com/huggingface/transformers/pull/29402\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     output \u001b[38;5;241m=\u001b[39m output \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[1;32mc:\\Users\\Maciej\\Documents\\VSCode\\Bluesky_firehose\\bluesky-firehose\\venv\\Lib\\site-packages\\transformers\\models\\gemma2\\modeling_gemma2.py:57\u001b[0m, in \u001b[0;36mGemma2RMSNorm._norm\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_norm\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "def clean_post(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)     # normalize whitespace\n",
    "    return text.strip()\n",
    "\n",
    "def generate_cluster_label(posts, max_new_tokens=16):\n",
    "    cleaned_posts = [clean_post(p) for p in posts[:5]]\n",
    "\n",
    "    prompt = (\n",
    "        \"Summarize the following 10 posts into 1 concise topic of 3â€“6 words in English. If a certain language is very prevelent include that as first word. \"\n",
    "        \"Do NOT include emojis, quotes, punctuation, hashtags, URLs, or extra commentary.\\n\\n\"\n",
    "        + \"\\n\".join(cleaned_posts)\n",
    "    )\n",
    "\n",
    "    user_prompt = {\"role\": \"user\", \"content\": prompt}\n",
    "    assistant_prompt = {\"role\": \"assistant\", \"content\": \"Provide a concise topic.\"}\n",
    "\n",
    "    chat_prompt = tokenizer.apply_chat_template(\n",
    "        [user_prompt, assistant_prompt],\n",
    "        tokenize=True,\n",
    "        return_tensors=\"pt\",\n",
    "        add_generation_prompt=True\n",
    "    ).to(device)  \n",
    "\n",
    "    outputs = model.generate(chat_prompt, max_new_tokens=max_new_tokens)\n",
    "    label = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    label = re.sub(r'\\s+', ' ', label).strip()\n",
    "    parts = re.split(r'model\\s+Provide a concise topic\\.?\\s*model', label, flags=re.IGNORECASE)\n",
    "    label = parts[-1].strip()\n",
    "    return label\n",
    "\n",
    "\n",
    "# ---------------- Generate cluster summaries ----------------\n",
    "cluster_summary = []\n",
    "rng = np.random.default_rng(seed=42)\n",
    "for i, c in enumerate(cluster_ids):\n",
    "    doc_idx = clusters[c]\n",
    "    if not doc_idx:\n",
    "        continue\n",
    "    print(f\"Cluster: {i}\")\n",
    "    # Get embeddings for this cluster\n",
    "    E_cluster = embeddings[doc_idx]\n",
    "    centroid = E_cluster.mean(axis=0)\n",
    "\n",
    "    # Compute cosine similarity of each post to the centroid\n",
    "    sim = cosine_similarity(E_cluster, centroid.reshape(1, -1)).ravel()\n",
    "\n",
    "    # Normalize similarities to probabilities (avoid divide-by-zero)\n",
    "    if sim.sum() == 0:\n",
    "        p = np.ones_like(sim) / len(sim)\n",
    "    else:\n",
    "        p = sim / sim.sum()\n",
    "\n",
    "    # Weighted random sampling (favoring central posts)\n",
    "    sample_size = min(10, len(doc_idx))\n",
    "    random_idx = rng.choice(doc_idx, size=sample_size, replace=False, p=p)\n",
    "\n",
    "    # Retrieve sampled posts\n",
    "    top_posts = [texts_clean[j] for j in random_idx]\n",
    "\n",
    "    # Generate a label or summary for the cluster\n",
    "    label_text = generate_cluster_label(top_posts)\n",
    "\n",
    "    # Store cluster metadata\n",
    "    centroid_2d = X_2d_centroids[i]\n",
    "    cluster_summary.append({\n",
    "        \"cluster\": int(c),\n",
    "        \"size\": len(doc_idx),\n",
    "        \"x\": float(centroid_2d[0]),\n",
    "        \"y\": float(centroid_2d[1]),\n",
    "        \"summary\": label_text\n",
    "    })\n",
    "\n",
    "# ---------------- Save cluster summary ----------------\n",
    "with open(os.path.join(OUTPUT_DIR, \"clusters.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(cluster_summary, f)\n",
    "\n",
    "print(f\"Saved {len(cluster_summary)} clusters with Gemma 2 labels to {os.path.join(OUTPUT_DIR, 'clusters.pkl')}\")\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563b4e7",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02828127",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"output\"\n",
    "\n",
    "# ---------------- Load cluster summary ----------------\n",
    "with open(os.path.join(OUTPUT_DIR, \"clusters.pkl\"), \"rb\") as f:\n",
    "    cluster_summary = pickle.load(f)\n",
    "\n",
    "df_plot = pd.DataFrame(cluster_summary)\n",
    "\n",
    "# ---------------- Scale positions to [0,1] for visualization ----------------\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_plot[[\"x\", \"y\"]] = scaler.fit_transform(df_plot[[\"x\", \"y\"]])\n",
    "\n",
    "# ---------------- Scale bubble size for visibility ----------------\n",
    "df_plot[\"size_scaled\"] = np.sqrt(df_plot[\"size\"])\n",
    "\n",
    "# ---------------- Assign random color per cluster ----------------\n",
    "unique_clusters = df_plot[\"cluster\"].unique()\n",
    "colors = px.colors.sample_colorscale(\n",
    "    \"Rainbow\", [i / (len(unique_clusters) - 1) for i in range(len(unique_clusters))]\n",
    ")\n",
    "color_map = dict(zip(unique_clusters, colors))\n",
    "df_plot[\"color\"] = df_plot[\"cluster\"].map(color_map)\n",
    "\n",
    "# ---------------- Add readable label column ----------------\n",
    "df_plot[\"label\"] = df_plot[\"cluster\"].apply(lambda c: f\"Cluster {c}\")\n",
    "\n",
    "# ---------------- Plot with summaries overlayed ----------------\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    size=\"size_scaled\",\n",
    "    color=\"color\",\n",
    "    text=\"summary\",  \n",
    "    hover_data={\"label\": True, \"size\": True, \"cluster\": True},\n",
    "    title=\"Clusters of Posts\",\n",
    "    width=1000,\n",
    "    height=700,\n",
    ")\n",
    "\n",
    "# ---------------- Improve visualization ----------------\n",
    "fig.update_traces(textposition=\"middle center\", textfont_size=10)\n",
    "fig.update_layout(\n",
    "    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "    showlegend=False  \n",
    ")\n",
    "\n",
    "# ---------------- Use browser renderer to avoid nbformat error ----------------\n",
    "pio.renderers.default = \"browser\"\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
